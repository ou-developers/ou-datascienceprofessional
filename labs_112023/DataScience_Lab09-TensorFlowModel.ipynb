{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f766c81",
   "metadata": {},
   "source": [
    "***\n",
    "# <font> Introduction to TensorFlowModel using Fashion MNIST dataset</font>\n",
    "<p style=\"margin-left:10%; margin-right:10%;\"> <font color=teal> \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff6a454",
   "metadata": {},
   "source": [
    "## Overview:\n",
    "\n",
    "The `TensorFlowModel` class in Accelerated Data Science (ADS) is designed to allow you to rapidly get a model into production. The `.prepare()` method creates the model artifacts that are needed to deploy a functioning model without you having to configure it or write code. However, it does allow you to customize the `score.py` file as needed. Simulate a call to a deployed model with the `.verify()` method. This method calls the `load_model()` and `predict()` functions in the `score.py` file. Using `.verify()` allows you to debug your `score.py` file without having to deploy a model. The `.save()` method pushes your `TensorFlowModel` and the model artifacts to the model catalog. The `.deploy()` method deploys the model to a REST endpoint for you. Finally, the `.predict()` method allows you to call the endpoint to perform model inference.\n",
    "\n",
    "These simples steps take your trained TensorFlow model and pushes it to production with just a few lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55203a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U oracle-ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54355d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65816b2f",
   "metadata": {},
   "source": [
    "These installations are done to view the list of available inbuilt datasets in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6986e08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832a0705",
   "metadata": {},
   "source": [
    "While importing, in addition to the required imports tensorflow_datasets and tensorflow_hub are also added "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51c6715",
   "metadata": {},
   "source": [
    "Please select the conda envionment tensorflow28_p38_cpu_v1 before proceeding further. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e0f594e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/tmp/ipykernel_22180/1471539920.py:12: DeprecationWarning: The `ads.common.model_metadata` is deprecated in `oracle-ads 2.6.8` and will be removed in future release. Use the `ads.model.model_metadata` instead.\n",
      "  from ads.common.model_metadata import UseCaseType\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ads\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_hub as hub\n",
    "import warnings\n",
    "\n",
    "from ads.catalog.model import ModelCatalog\n",
    "from ads.common.model_metadata import UseCaseType\n",
    "\n",
    "from ads.dataset.factory import DatasetFactory\n",
    "from ads.model.framework.tensorflow_model import TensorFlowModel\n",
    "from shutil import rmtree\n",
    "ads.set_auth(auth='resource_principal')\n",
    "\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.ERROR)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b22e414f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  O  o-o   o-o\n",
      " / \\ |  \\ |\n",
      "o---o|   O o-o\n",
      "|   ||  /     |\n",
      "o   oo-o  o--o\n",
      "\n",
      "ads v2.8.11\n",
      "oci v2.114.0\n",
      "ocifs v1.1.3\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ads.hello()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b28f4a6",
   "metadata": {},
   "source": [
    "The list_builders() method displays a list of available datasets under tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbd3e7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-27 12:01:45.488261: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:absl:Could not refresh the package index (GCS unavailable): All 10 retry attempts failed. The last failure: Error executing an HTTP request: libcurl code 60 meaning 'SSL peer certificate or SSH remote key was not OK', error details: SSL certificate problem: unable to get local issuer certificate\n",
      "\t when reading metadata of gs://tfds-data/community-datasets-list.jsonl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['abstract_reasoning',\n",
       " 'accentdb',\n",
       " 'aeslc',\n",
       " 'aflw2k3d',\n",
       " 'ag_news_subset',\n",
       " 'ai2_arc',\n",
       " 'ai2_arc_with_ir',\n",
       " 'amazon_us_reviews',\n",
       " 'anli',\n",
       " 'answer_equivalence',\n",
       " 'arc',\n",
       " 'asqa',\n",
       " 'asset',\n",
       " 'assin2',\n",
       " 'bair_robot_pushing_small',\n",
       " 'bccd',\n",
       " 'beans',\n",
       " 'bee_dataset',\n",
       " 'beir',\n",
       " 'big_patent',\n",
       " 'bigearthnet',\n",
       " 'billsum',\n",
       " 'binarized_mnist',\n",
       " 'binary_alpha_digits',\n",
       " 'ble_wind_field',\n",
       " 'blimp',\n",
       " 'booksum',\n",
       " 'bool_q',\n",
       " 'bucc',\n",
       " 'c4',\n",
       " 'c4_wsrs',\n",
       " 'caltech101',\n",
       " 'caltech_birds2010',\n",
       " 'caltech_birds2011',\n",
       " 'cardiotox',\n",
       " 'cars196',\n",
       " 'cassava',\n",
       " 'cats_vs_dogs',\n",
       " 'celeb_a',\n",
       " 'celeb_a_hq',\n",
       " 'cfq',\n",
       " 'cherry_blossoms',\n",
       " 'chexpert',\n",
       " 'cifar10',\n",
       " 'cifar100',\n",
       " 'cifar100_n',\n",
       " 'cifar10_1',\n",
       " 'cifar10_corrupted',\n",
       " 'cifar10_n',\n",
       " 'citrus_leaves',\n",
       " 'cityscapes',\n",
       " 'civil_comments',\n",
       " 'clevr',\n",
       " 'clic',\n",
       " 'clinc_oos',\n",
       " 'cmaterdb',\n",
       " 'cnn_dailymail',\n",
       " 'coco',\n",
       " 'coco_captions',\n",
       " 'coil100',\n",
       " 'colorectal_histology',\n",
       " 'colorectal_histology_large',\n",
       " 'common_voice',\n",
       " 'conll2002',\n",
       " 'conll2003',\n",
       " 'controlled_noisy_web_labels',\n",
       " 'coqa',\n",
       " 'cos_e',\n",
       " 'cosmos_qa',\n",
       " 'covid19',\n",
       " 'covid19sum',\n",
       " 'crema_d',\n",
       " 'criteo',\n",
       " 'cs_restaurants',\n",
       " 'curated_breast_imaging_ddsm',\n",
       " 'cycle_gan',\n",
       " 'd4rl_adroit_door',\n",
       " 'd4rl_adroit_hammer',\n",
       " 'd4rl_adroit_pen',\n",
       " 'd4rl_adroit_relocate',\n",
       " 'd4rl_antmaze',\n",
       " 'd4rl_mujoco_ant',\n",
       " 'd4rl_mujoco_halfcheetah',\n",
       " 'd4rl_mujoco_hopper',\n",
       " 'd4rl_mujoco_walker2d',\n",
       " 'dart',\n",
       " 'davis',\n",
       " 'deep1b',\n",
       " 'deep_weeds',\n",
       " 'definite_pronoun_resolution',\n",
       " 'dementiabank',\n",
       " 'diabetic_retinopathy_detection',\n",
       " 'diamonds',\n",
       " 'div2k',\n",
       " 'dmlab',\n",
       " 'doc_nli',\n",
       " 'dolphin_number_word',\n",
       " 'domainnet',\n",
       " 'downsampled_imagenet',\n",
       " 'drop',\n",
       " 'dsprites',\n",
       " 'dtd',\n",
       " 'duke_ultrasound',\n",
       " 'e2e_cleaned',\n",
       " 'efron_morris75',\n",
       " 'emnist',\n",
       " 'eraser_multi_rc',\n",
       " 'esnli',\n",
       " 'eurosat',\n",
       " 'fashion_mnist',\n",
       " 'flic',\n",
       " 'flores',\n",
       " 'food101',\n",
       " 'forest_fires',\n",
       " 'fuss',\n",
       " 'gap',\n",
       " 'geirhos_conflict_stimuli',\n",
       " 'gem',\n",
       " 'genomics_ood',\n",
       " 'german_credit_numeric',\n",
       " 'gigaword',\n",
       " 'glove100_angular',\n",
       " 'glue',\n",
       " 'goemotions',\n",
       " 'gov_report',\n",
       " 'gpt3',\n",
       " 'gref',\n",
       " 'groove',\n",
       " 'grounded_scan',\n",
       " 'gsm8k',\n",
       " 'gtzan',\n",
       " 'gtzan_music_speech',\n",
       " 'hellaswag',\n",
       " 'higgs',\n",
       " 'hillstrom',\n",
       " 'horses_or_humans',\n",
       " 'howell',\n",
       " 'i_naturalist2017',\n",
       " 'i_naturalist2018',\n",
       " 'i_naturalist2021',\n",
       " 'imagenet2012',\n",
       " 'imagenet2012_corrupted',\n",
       " 'imagenet2012_fewshot',\n",
       " 'imagenet2012_multilabel',\n",
       " 'imagenet2012_real',\n",
       " 'imagenet2012_subset',\n",
       " 'imagenet_a',\n",
       " 'imagenet_lt',\n",
       " 'imagenet_pi',\n",
       " 'imagenet_r',\n",
       " 'imagenet_resized',\n",
       " 'imagenet_sketch',\n",
       " 'imagenet_v2',\n",
       " 'imagenette',\n",
       " 'imagewang',\n",
       " 'imdb_reviews',\n",
       " 'irc_disentanglement',\n",
       " 'iris',\n",
       " 'istella',\n",
       " 'kddcup99',\n",
       " 'kitti',\n",
       " 'kmnist',\n",
       " 'laion400m',\n",
       " 'lambada',\n",
       " 'lfw',\n",
       " 'librispeech',\n",
       " 'librispeech_lm',\n",
       " 'libritts',\n",
       " 'ljspeech',\n",
       " 'lm1b',\n",
       " 'locomotion',\n",
       " 'lost_and_found',\n",
       " 'lsun',\n",
       " 'lvis',\n",
       " 'malaria',\n",
       " 'math_dataset',\n",
       " 'math_qa',\n",
       " 'mctaco',\n",
       " 'media_sum',\n",
       " 'mlqa',\n",
       " 'mnist',\n",
       " 'mnist_corrupted',\n",
       " 'movie_lens',\n",
       " 'movie_rationales',\n",
       " 'movielens',\n",
       " 'moving_mnist',\n",
       " 'mrqa',\n",
       " 'mslr_web',\n",
       " 'mt_opt',\n",
       " 'mtnt',\n",
       " 'multi_news',\n",
       " 'multi_nli',\n",
       " 'multi_nli_mismatch',\n",
       " 'natural_instructions',\n",
       " 'natural_questions',\n",
       " 'natural_questions_open',\n",
       " 'newsroom',\n",
       " 'nsynth',\n",
       " 'nyu_depth_v2',\n",
       " 'ogbg_molpcba',\n",
       " 'omniglot',\n",
       " 'open_images_challenge2019_detection',\n",
       " 'open_images_v4',\n",
       " 'openbookqa',\n",
       " 'opinion_abstracts',\n",
       " 'opinosis',\n",
       " 'opus',\n",
       " 'oxford_flowers102',\n",
       " 'oxford_iiit_pet',\n",
       " 'para_crawl',\n",
       " 'pass',\n",
       " 'patch_camelyon',\n",
       " 'paws_wiki',\n",
       " 'paws_x_wiki',\n",
       " 'penguins',\n",
       " 'pet_finder',\n",
       " 'pg19',\n",
       " 'piqa',\n",
       " 'places365_small',\n",
       " 'placesfull',\n",
       " 'plant_leaves',\n",
       " 'plant_village',\n",
       " 'plantae_k',\n",
       " 'protein_net',\n",
       " 'q_re_cc',\n",
       " 'qa4mre',\n",
       " 'qasc',\n",
       " 'quac',\n",
       " 'quality',\n",
       " 'quickdraw_bitmap',\n",
       " 'race',\n",
       " 'radon',\n",
       " 'reddit',\n",
       " 'reddit_disentanglement',\n",
       " 'reddit_tifu',\n",
       " 'ref_coco',\n",
       " 'resisc45',\n",
       " 'rlu_atari',\n",
       " 'rlu_atari_checkpoints',\n",
       " 'rlu_atari_checkpoints_ordered',\n",
       " 'rlu_control_suite',\n",
       " 'rlu_dmlab_explore_object_rewards_few',\n",
       " 'rlu_dmlab_explore_object_rewards_many',\n",
       " 'rlu_dmlab_rooms_select_nonmatching_object',\n",
       " 'rlu_dmlab_rooms_watermaze',\n",
       " 'rlu_dmlab_seekavoid_arena01',\n",
       " 'rlu_locomotion',\n",
       " 'rlu_rwrl',\n",
       " 'robomimic_mg',\n",
       " 'robomimic_mh',\n",
       " 'robomimic_ph',\n",
       " 'robonet',\n",
       " 'robosuite_panda_pick_place_can',\n",
       " 'rock_paper_scissors',\n",
       " 'rock_you',\n",
       " 's3o4d',\n",
       " 'salient_span_wikipedia',\n",
       " 'samsum',\n",
       " 'savee',\n",
       " 'scan',\n",
       " 'scene_parse150',\n",
       " 'schema_guided_dialogue',\n",
       " 'sci_tail',\n",
       " 'scicite',\n",
       " 'scientific_papers',\n",
       " 'scrolls',\n",
       " 'sentiment140',\n",
       " 'shapes3d',\n",
       " 'sift1m',\n",
       " 'simpte',\n",
       " 'siscore',\n",
       " 'smallnorb',\n",
       " 'smartwatch_gestures',\n",
       " 'snli',\n",
       " 'so2sat',\n",
       " 'speech_commands',\n",
       " 'spoken_digit',\n",
       " 'squad',\n",
       " 'squad_question_generation',\n",
       " 'stanford_dogs',\n",
       " 'stanford_online_products',\n",
       " 'star_cfq',\n",
       " 'starcraft_video',\n",
       " 'stl10',\n",
       " 'story_cloze',\n",
       " 'summscreen',\n",
       " 'sun397',\n",
       " 'super_glue',\n",
       " 'svhn_cropped',\n",
       " 'symmetric_solids',\n",
       " 'tao',\n",
       " 'tatoeba',\n",
       " 'ted_hrlr_translate',\n",
       " 'ted_multi_translate',\n",
       " 'tedlium',\n",
       " 'tf_flowers',\n",
       " 'the300w_lp',\n",
       " 'tiny_shakespeare',\n",
       " 'titanic',\n",
       " 'trec',\n",
       " 'trivia_qa',\n",
       " 'tydi_qa',\n",
       " 'uc_merced',\n",
       " 'ucf101',\n",
       " 'unified_qa',\n",
       " 'universal_dependencies',\n",
       " 'unnatural_instructions',\n",
       " 'user_libri_audio',\n",
       " 'user_libri_text',\n",
       " 'vctk',\n",
       " 'visual_domain_decathlon',\n",
       " 'voc',\n",
       " 'voxceleb',\n",
       " 'voxforge',\n",
       " 'waymo_open_dataset',\n",
       " 'web_graph',\n",
       " 'web_nlg',\n",
       " 'web_questions',\n",
       " 'webvid',\n",
       " 'wider_face',\n",
       " 'wiki40b',\n",
       " 'wiki_auto',\n",
       " 'wiki_bio',\n",
       " 'wiki_dialog',\n",
       " 'wiki_table_questions',\n",
       " 'wiki_table_text',\n",
       " 'wikiann',\n",
       " 'wikihow',\n",
       " 'wikipedia',\n",
       " 'wikipedia_toxicity_subtypes',\n",
       " 'wine_quality',\n",
       " 'winogrande',\n",
       " 'wit',\n",
       " 'wit_kaggle',\n",
       " 'wmt13_translate',\n",
       " 'wmt14_translate',\n",
       " 'wmt15_translate',\n",
       " 'wmt16_translate',\n",
       " 'wmt17_translate',\n",
       " 'wmt18_translate',\n",
       " 'wmt19_translate',\n",
       " 'wmt_t2t_translate',\n",
       " 'wmt_translate',\n",
       " 'wordnet',\n",
       " 'wsc273',\n",
       " 'xnli',\n",
       " 'xquad',\n",
       " 'xsum',\n",
       " 'xtreme_pawsx',\n",
       " 'xtreme_pos',\n",
       " 'xtreme_s',\n",
       " 'xtreme_xnli',\n",
       " 'yahoo_ltrc',\n",
       " 'yelp_polarity_reviews',\n",
       " 'yes_no',\n",
       " 'youtube_vis']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfds.list_builders()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005bafb4",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "# Introduction\n",
    "\n",
    "<a id=\"intro_dataset\"></a>\n",
    "## Dataset\n",
    "\n",
    "The [Fashion_MNIST](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/fashion_mnist) is a dataset of Zalando's article images—consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. Zalando intends Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\n",
    "\n",
    "\n",
    "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255. The training and test data sets have 785 columns. The first column consists of the class labels (see above), and represents the article of clothing. The rest of the columns contain the pixel-values of the associated image.\n",
    "\n",
    "**Note**: This notebook requires public internet access to download the sample dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63d06d4",
   "metadata": {},
   "source": [
    "<a id='create'></a>\n",
    "# Create a TensorFlow Model\n",
    "\n",
    "The next cell creates a `TFModel` class that loads in the MNIST data using a public internet connection. The data is then scaled to be between zero and one. To reduce the computational time needed to generate the model, only the first 10,000 training samples are used.\n",
    "\n",
    "The TensorFlow model has an input layer of 784 nodes (28x28), a single dense, hidden layer of 128 nodes with a RELU activation function. The output layer consists of 10 dense nodes, one for each of the ten possible digits. A 20% drop-out is used to reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0caacab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFModel:\n",
    "\n",
    "    fmnist = tf.keras.datasets.fashion_mnist\n",
    "    (x_train, y_train), (x_test, y_test) = fmnist.load_data() # Load data\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0        # Scale between 0 and 1\n",
    "    x_train, y_train = x_train[:10000], y_train[:10000]      # Reduce training data size\n",
    "\n",
    "    def training(self):\n",
    "        model = tf.keras.models.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "                tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "                tf.keras.layers.Dropout(0.2),\n",
    "                tf.keras.layers.Dense(10),\n",
    "            ]\n",
    "        )\n",
    "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        model.compile(optimizer=\"adam\", loss=loss_fn, metrics=[\"accuracy\"])\n",
    "        model.fit(self.x_train, self.y_train, epochs=1)\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7236d06d",
   "metadata": {},
   "source": [
    "The next cell builds and trains the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e0777ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-27 12:06:09.654672: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-27 12:06:09.655491: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 7ms/step - loss: 0.7780 - accuracy: 0.7228\n"
     ]
    }
   ],
   "source": [
    "model = TFModel().training()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849a4d94",
   "metadata": {},
   "source": [
    "Once the model has been trained, you use the `.predict()` method to make predictions on a subset of the test dataset. Each prediction outputs ten values because there are ten nodes on the output layer. The node with the highest value is the digit that the model predicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec7aa4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.8638165, -4.98483  , -3.4681497, -5.0042253, -2.9476   ,\n",
       "         1.5224715, -3.386241 ,  1.6353451, -0.4474761,  3.4194736]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(TFModel().x_test[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34cd105",
   "metadata": {},
   "source": [
    "<a id='serialize'></a>\n",
    "# TensorFlow Framework Serialization\n",
    "\n",
    "The TensorFlow framework makes it easy to deploy a TensorFlow model into production. The `TensorFlowModel()` constructor takes a TensorFlow model and converts it into a `TensorFlowModel` object. To deploy the model into production, you must prepare the model artifact, verify that the artifact works, save the model to the model catalog, and then deploy it.\n",
    "\n",
    "ADS provides a number of methods that greatly simplify the model deployment process. It also provides the `.summary_status()` method that provides a dataframe that defines the steps, status, and detailed information about each step. \n",
    "\n",
    "<a id='serialize_tensorflowmodel'></a>\n",
    "## Create a TensorFlowModel\n",
    "\n",
    "In this notebook, a `keras.engine.sequential.Sequential` object is created. The `TensorFlowModel()` constructor takes the `keras.engine.sequential.Sequential` object along with the path that you want to use to store the model artifacts. A `TensorFlowModel` object is returned, and it's used to manage the deployment.\n",
    "\n",
    "The next cell creates a model artifact directory. This directory is used to store the artifacts that are needed to deploy the model. It also creates the `TensorFlowModel` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5331277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model artifact director: /tmp/tmphp0ijmyi\n",
      "WARNING:ads.common:In the future model input will be serialized by `cloudpickle` by default. Currently, model input are serialized into a dictionary containing serialized input data and original data type information.Set `model_input_serializer=\"cloudpickle\"` to use cloudpickle model input serializer.\n"
     ]
    }
   ],
   "source": [
    "artifact_dir = tempfile.mkdtemp()\n",
    "print(f\"Model artifact director: {artifact_dir}\")\n",
    "tf_model = TensorFlowModel(estimator=model, artifact_dir=artifact_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5f9176",
   "metadata": {},
   "source": [
    "The `.summary_status()` method of the `TensorFlowModel` class is a handy method to keep track of the progress that you are making in deploying the model. It creates a dataframe that lists the deployment steps, their status, and details about them. The next cell returns the summary status dataframe. It shows that the initiate step has been completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05b59da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Actions Needed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Step</th>\n",
       "      <th>Status</th>\n",
       "      <th>Details</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>initiate</th>\n",
       "      <th>Done</th>\n",
       "      <th>Initiated the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">prepare()</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Available</th>\n",
       "      <th>Generated runtime.yaml</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generated score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serialized model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Populated metadata(Custom, Taxonomy and Provenance)</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verify()</th>\n",
       "      <th>Not Available</th>\n",
       "      <th>Local tested .predict from score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">save()</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Not Available</th>\n",
       "      <th>Conducted Introspect Test</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uploaded artifact to model catalog</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deploy()</th>\n",
       "      <th>UNKNOWN</th>\n",
       "      <th>Deployed the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict()</th>\n",
       "      <th>Not Available</th>\n",
       "      <th>Called deployment predict endpoint</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            Actions Needed\n",
       "Step      Status        Details                                                           \n",
       "initiate  Done          Initiated the model                                               \n",
       "prepare() Available     Generated runtime.yaml                                            \n",
       "                        Generated score.py                                                \n",
       "                        Serialized model                                                  \n",
       "                        Populated metadata(Custom, Taxonomy and Provenance)               \n",
       "verify()  Not Available Local tested .predict from score.py                               \n",
       "save()    Not Available Conducted Introspect Test                                         \n",
       "                        Uploaded artifact to model catalog                                \n",
       "deploy()  UNKNOWN       Deployed the model                                                \n",
       "predict() Not Available Called deployment predict endpoint                                "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_model.summary_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53350363",
   "metadata": {},
   "source": [
    "<a id='serialize_prepare'></a>\n",
    "## Prepare\n",
    "\n",
    "The prepare step is performed by the `.prepare()` method of the `TensorFlowModel` class. It creates a number of customized files that are used to run the model once it is deployed. These include:\n",
    "\n",
    "* `input_schema.json`: A JSON file that defines the nature of the features of the `X_sample` data. It includes metadata such as the data type, name, constraints, summary statistics, feature type, and more.\n",
    "* `model.h5`: This is the default filename of the serialized model. You can change it with the `model_file_name` attribute. By default, the model is stored in an h5 file. You can use the `as_onnx` parameter to save the model in the ONNX format.\n",
    "* `output_schema.json`: A JSON file that defines the nature of the dependent variable in the `y_sample` data. It includes metadata such as the data type, name, constraints, summary statistics, feature type, and more.\n",
    "* `runtime.yaml`: This file contains information that is needed to set up the runtime environment on the deployment server. It has information about which conda environment was used to train the model, and what environment should be used to deploy the model. The file also specifies what version of Python should be used.\n",
    "* `score.py`: This script contains the `load_model()` and `predict()` functions. The `load_model()` function understands the format the model file was saved in, and loads it into memory. The `.predict()` method is used to make inferences in a deployed model. There are also hooks that allow you to perform operations before and after inference. You are able to modify this script to fit your specific needs.\n",
    "\n",
    "To create the model artifacts, you use the `.prepare()` method. There are a number of parameters that allow you to store model provenance information. In the next cell, the `conda_env` variable defines the slug of the conda environment that was used to train the model, and the conda environment to use for deployment. Note that you can only pass in slugs to `inference_conda_env` or `training_conda_env` if it's a service environment. Otherwise, you must pass in the full path of the conda environment along with the python version through `inference_python_version` and `training_python_version`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf599428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:ADS:Cannot convert the data to pandas dataframe, hence the schema was not auto generated.                                                                                                ?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "algorithm: Sequential\n",
       "artifact_dir:\n",
       "  /tmp/tmphp0ijmyi:\n",
       "  - - .model-ignore\n",
       "    - score.py\n",
       "    - runtime.yaml\n",
       "    - output_schema.json\n",
       "    - model.h5\n",
       "framework: tensorflow\n",
       "model_deployment_id: null\n",
       "model_id: null"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#conda_env = \"generalml_p38_cpu_v1\"\n",
    "\n",
    "tf_model.prepare(\n",
    "    inference_conda_env=\"tensorflow28_p38_cpu_v1\" ,\n",
    "    training_conda_env=\"tensorflow28_p38_cpu_v1\",\n",
    "    use_case_type=UseCaseType.MULTINOMIAL_CLASSIFICATION,\n",
    "    X_sample=TFModel().x_test,\n",
    "    y_sample=TFModel().y_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2157e5ba",
   "metadata": {},
   "source": [
    "The next cell uses the `.summary_status()` method to show you that the prepare step finished, and what tasks were completed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e15bdf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Actions Needed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Step</th>\n",
       "      <th>Status</th>\n",
       "      <th>Details</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>initiate</th>\n",
       "      <th>Done</th>\n",
       "      <th>Initiated the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">prepare()</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Done</th>\n",
       "      <th>Generated runtime.yaml</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generated score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serialized model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Populated metadata(Custom, Taxonomy and Provenance)</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verify()</th>\n",
       "      <th>Available</th>\n",
       "      <th>Local tested .predict from score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">save()</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Available</th>\n",
       "      <th>Conducted Introspect Test</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uploaded artifact to model catalog</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deploy()</th>\n",
       "      <th>UNKNOWN</th>\n",
       "      <th>Deployed the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict()</th>\n",
       "      <th>Not Available</th>\n",
       "      <th>Called deployment predict endpoint</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            Actions Needed\n",
       "Step      Status        Details                                                           \n",
       "initiate  Done          Initiated the model                                               \n",
       "prepare() Done          Generated runtime.yaml                                            \n",
       "                        Generated score.py                                                \n",
       "                        Serialized model                                                  \n",
       "                        Populated metadata(Custom, Taxonomy and Provenance)               \n",
       "verify()  Available     Local tested .predict from score.py                               \n",
       "save()    Available     Conducted Introspect Test                                         \n",
       "                        Uploaded artifact to model catalog                                \n",
       "deploy()  UNKNOWN       Deployed the model                                                \n",
       "predict() Not Available Called deployment predict endpoint                                "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_model.summary_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b8079f",
   "metadata": {},
   "source": [
    "The `.prepare()` method has created the following fully functional files. However, you can modify them to fit your specific needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fccb3d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.model-ignore', 'score.py', 'runtime.yaml', 'output_schema.json', 'model.h5']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(artifact_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5f6b91",
   "metadata": {},
   "source": [
    "Once the artifacts have been created, there are a number of attributes in the `TensorFlowModel` object that provide metadata about the model. The `.runtime` attribute details the model deployment settings and model provenance data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a02c7c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "model_artifact_version: '3.0'\n",
       "model_deployment:\n",
       "  inference_conda_env:\n",
       "    inference_env_path: oci://service-conda-packs@id19sfcrra6z/service_pack/cpu/TensorFlow_2.8_for_CPU_on_Python_3.8/1.0/tensorflow28_p38_cpu_v1\n",
       "    inference_env_slug: tensorflow28_p38_cpu_v1\n",
       "    inference_env_type: data_science\n",
       "    inference_python_version: '3.8'\n",
       "model_provenance:\n",
       "  project_ocid: ''\n",
       "  tenancy_ocid: ''\n",
       "  training_code:\n",
       "    artifact_directory: /tmp/tmphp0ijmyi\n",
       "  training_compartment_ocid: ''\n",
       "  training_conda_env:\n",
       "    training_env_path: oci://service-conda-packs@id19sfcrra6z/service_pack/cpu/TensorFlow_2.8_for_CPU_on_Python_3.8/1.0/tensorflow28_p38_cpu_v1\n",
       "    training_env_slug: tensorflow28_p38_cpu_v1\n",
       "    training_env_type: data_science\n",
       "    training_python_version: '3.8'\n",
       "  training_region: ''\n",
       "  training_resource_ocid: ''\n",
       "  user_ocid: ''\n",
       "  vm_image_internal_id: ''"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_model.runtime_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e6ced9",
   "metadata": {},
   "source": [
    "The `.schema_input` attribute provides metadata on the features that were used to train the model. You can use this information to determine what data must be provided to make model inferences. Each feature in the model has a section that defines the dtype, feature type, name, and if it is required. The metadata also includes the summary statistics associated with the feature type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "056ca0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "schema: []\n",
       "version: '1.1'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_model.schema_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b5b3ee",
   "metadata": {},
   "source": [
    "The `.metadata_custom` attribute provides custom metadata that contains information on the category of the metadata, description, key, and value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "256fc352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data:\n",
       "- category: Training Environment\n",
       "  description: The slug name of the training conda environment.\n",
       "  key: SlugName\n",
       "  value: tensorflow28_p38_cpu_v1\n",
       "- category: Other\n",
       "  description: ''\n",
       "  key: ClientLibrary\n",
       "  value: ADS\n",
       "- category: Training Environment\n",
       "  description: The URI of the training conda environment.\n",
       "  key: CondaEnvironmentPath\n",
       "  value: oci://service-conda-packs@id19sfcrra6z/service_pack/cpu/TensorFlow_2.8_for_CPU_on_Python_3.8/1.0/tensorflow28_p38_cpu_v1\n",
       "- category: Training Environment\n",
       "  description: The list of files located in artifacts folder.\n",
       "  key: ModelArtifacts\n",
       "  value: .model-ignore, score.py, runtime.yaml, model.h5\n",
       "- category: Other\n",
       "  description: The model file name.\n",
       "  key: ModelFileName\n",
       "  value: model.h5\n",
       "- category: Training Environment\n",
       "  description: The conda environment type, can be published or datascience.\n",
       "  key: EnvironmentType\n",
       "  value: data_science\n",
       "- category: Training Profile\n",
       "  description: The model serialization format.\n",
       "  key: ModelSerializationFormat\n",
       "  value: h5\n",
       "- category: Training Environment\n",
       "  description: The conda environment where the model was trained.\n",
       "  key: CondaEnvironment\n",
       "  value: oci://service-conda-packs@id19sfcrra6z/service_pack/cpu/TensorFlow_2.8_for_CPU_on_Python_3.8/1.0/tensorflow28_p38_cpu_v1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_model.metadata_custom\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dffa01",
   "metadata": {},
   "source": [
    "The `.metadata_provenance` contains information about the code and training data that was used to create the model. This information is most useful when a Git repository is being used to manage the code for training the model. This is considered a best practice because it allows you to do things like reproduce a model, perform forensic on the model, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8e695da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "artifact_dir: null\n",
       "git_branch: null\n",
       "git_commit: null\n",
       "repository_url: null\n",
       "training_id: null\n",
       "training_script_path: null"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_model.metadata_provenance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442c40d4",
   "metadata": {},
   "source": [
    "The `.metadata_taxonomy` is a key-value store that has information about the classification or taxonomy of the model. This can include information such as the model framework, use case type, hyperparameters, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f639bc51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data:\n",
       "- key: UseCaseType\n",
       "  value: multinomial_classification\n",
       "- key: Framework\n",
       "  value: tensorflow\n",
       "- key: ArtifactTestResults\n",
       "  value: null\n",
       "- key: Hyperparameters\n",
       "  value: null\n",
       "- key: FrameworkVersion\n",
       "  value: 2.8.2\n",
       "- key: Algorithm\n",
       "  value: Sequential"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_model.metadata_taxonomy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a28d70",
   "metadata": {},
   "source": [
    "<a id='serialize_verify'></a>\n",
    "## Verify\n",
    "\n",
    "If you modify the `score.py` file that is part of the model artifacts, then you should verify it. The verify step allows you to test those changes without having to deploy the model. This allows you to debug your code without having to save the model to the model catalog, and then deploy it. The `.verify()` method takes a set of test parameters and performs the prediction by calling the `predict` function in `score.py`. It also runs the `load_model` function.\n",
    "\n",
    "The next cell simulates a call to a deployed model without having to actually deploy the model. It passes in test values and returns the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d25c82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading model.h5 from model directory /tmp/tmphp0ijmyi ...\n",
      "Model is successfully loaded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prediction': [[-3.863816499710083,\n",
       "   -4.984829902648926,\n",
       "   -3.4681506156921387,\n",
       "   -5.004225254058838,\n",
       "   -2.9476001262664795,\n",
       "   1.5224714279174805,\n",
       "   -3.3862407207489014,\n",
       "   1.6353453397750854,\n",
       "   -0.447476327419281,\n",
       "   3.419473171234131]]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_model.verify(TFModel().x_test[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85904dd",
   "metadata": {},
   "source": [
    "Update the `.summary_status()` method to show that the verify step has been completed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c870c3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Actions Needed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Step</th>\n",
       "      <th>Status</th>\n",
       "      <th>Details</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>initiate</th>\n",
       "      <th>Done</th>\n",
       "      <th>Initiated the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">prepare()</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Done</th>\n",
       "      <th>Generated runtime.yaml</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generated score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serialized model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Populated metadata(Custom, Taxonomy and Provenance)</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verify()</th>\n",
       "      <th>Done</th>\n",
       "      <th>Local tested .predict from score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">save()</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Available</th>\n",
       "      <th>Conducted Introspect Test</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uploaded artifact to model catalog</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deploy()</th>\n",
       "      <th>UNKNOWN</th>\n",
       "      <th>Deployed the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict()</th>\n",
       "      <th>Not Available</th>\n",
       "      <th>Called deployment predict endpoint</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            Actions Needed\n",
       "Step      Status        Details                                                           \n",
       "initiate  Done          Initiated the model                                               \n",
       "prepare() Done          Generated runtime.yaml                                            \n",
       "                        Generated score.py                                                \n",
       "                        Serialized model                                                  \n",
       "                        Populated metadata(Custom, Taxonomy and Provenance)               \n",
       "verify()  Done          Local tested .predict from score.py                               \n",
       "save()    Available     Conducted Introspect Test                                         \n",
       "                        Uploaded artifact to model catalog                                \n",
       "deploy()  UNKNOWN       Deployed the model                                                \n",
       "predict() Not Available Called deployment predict endpoint                                "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_model.summary_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d624450",
   "metadata": {},
   "source": [
    "<a id='serialize_save'></a>\n",
    "## Save\n",
    "\n",
    "Once you are satisfied with the performance of the model and have verified that the `score.py` file is working, you save the model to the model catalog. You do this with the `.save()` method on a `TensorFlowModel` object. This bundles up the model artifact that you have created, and deploys it to the model catalog. It returns the model OCID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aeea099a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading model.h5 from model directory /tmp/tmphp0ijmyi ...\n",
      "Model is successfully loaded.\n",
      "['.model-ignore', 'score.py', 'runtime.yaml', 'output_schema.json', 'model.h5']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = tf_model.save(display_name='Demo TensorFlowModel model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5a1a06",
   "metadata": {},
   "source": [
    "<a id='serialize_deploy'></a>\n",
    "## Deploy\n",
    "\n",
    "When the model is in the model catalog, you can use the `.deploy()` method of a `TensorFlowModel` object to deploy the model. This method allows you to specify the attributes of the deployment such as the display name, description, instance type and count, the maximum bandwidth, and logging groups. The next cell deploys the model with the default settings, except for the custom display name. The `.deploy()` method returns a `ModelDeployment` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ae5ee12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deploy = tf_model.deploy(display_name='Demo TensorFlowModel deployment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20671bd",
   "metadata": {},
   "source": [
    "After deployment, the `.summary_status()` method shows that the model is `ACTIVE` and the `predict()` method is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c95dd87f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Actions Needed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Step</th>\n",
       "      <th>Status</th>\n",
       "      <th>Details</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>initiate</th>\n",
       "      <th>Done</th>\n",
       "      <th>Initiated the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">prepare()</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Done</th>\n",
       "      <th>Generated runtime.yaml</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generated score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serialized model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Populated metadata(Custom, Taxonomy and Provenance)</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verify()</th>\n",
       "      <th>Done</th>\n",
       "      <th>Local tested .predict from score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">save()</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Done</th>\n",
       "      <th>Conducted Introspect Test</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uploaded artifact to model catalog</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deploy()</th>\n",
       "      <th>ACTIVE</th>\n",
       "      <th>Deployed the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict()</th>\n",
       "      <th>Available</th>\n",
       "      <th>Called deployment predict endpoint</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        Actions Needed\n",
       "Step      Status    Details                                                           \n",
       "initiate  Done      Initiated the model                                               \n",
       "prepare() Done      Generated runtime.yaml                                            \n",
       "                    Generated score.py                                                \n",
       "                    Serialized model                                                  \n",
       "                    Populated metadata(Custom, Taxonomy and Provenance)               \n",
       "verify()  Done      Local tested .predict from score.py                               \n",
       "save()    Done      Conducted Introspect Test                                         \n",
       "                    Uploaded artifact to model catalog                                \n",
       "deploy()  ACTIVE    Deployed the model                                                \n",
       "predict() Available Called deployment predict endpoint                                "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_model.summary_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1079f3fd",
   "metadata": {},
   "source": [
    "<a id='serialize_predict'></a>\n",
    "## Predict\n",
    "\n",
    "In the <a href='#create'>Create a TensorFlow Model</a> section, you used the `model.predict()` method where `model` is an `ADSModel` object. This did the inference using the local model. Now that the `TensorFlowModel` model has been deployed, you can do the same thing using similar syntax with the `.predict()` method on a `TensorFlowModel`.\n",
    "\n",
    "After the deployment is active, you can call `predict()` on the `TensorFlowModel` object to send request to the deployed endpoint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1c42c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-3.863816499710083,\n",
       "  -4.984829902648926,\n",
       "  -3.4681496620178223,\n",
       "  -5.004225254058838,\n",
       "  -2.9475998878479004,\n",
       "  1.52247154712677,\n",
       "  -3.3862409591674805,\n",
       "  1.6353451013565063,\n",
       "  -0.4474760890007019,\n",
       "  3.419473648071289]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_model.predict(TFModel().x_test[0:1])['prediction']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a123c9d",
   "metadata": {},
   "source": [
    "<a id='clean_up'></a>\n",
    "# Clean Up\n",
    "\n",
    "This notebook created a model deployment and a model. This section deletes those resources. \n",
    "\n",
    "The model deployment must be deleted before the model can be deleted. You use the `.delete_deployment()` method on the `TensorFlowModel` object to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2944c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "delete = tf_model.delete_deployment(wait_for_completion=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae950347",
   "metadata": {},
   "source": [
    "After the model deployment has been deleted, the `.summary_status()` method shows that the model has been deleted and that the `predict()` method is not available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a493a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Actions Needed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Step</th>\n",
       "      <th>Status</th>\n",
       "      <th>Details</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>initiate</th>\n",
       "      <th>Done</th>\n",
       "      <th>Initiated the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">prepare()</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Done</th>\n",
       "      <th>Generated runtime.yaml</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generated score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serialized model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Populated metadata(Custom, Taxonomy and Provenance)</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verify()</th>\n",
       "      <th>Done</th>\n",
       "      <th>Local tested .predict from score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">save()</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Done</th>\n",
       "      <th>Conducted Introspect Test</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uploaded artifact to model catalog</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deploy()</th>\n",
       "      <th>DELETED</th>\n",
       "      <th>Deployed the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict()</th>\n",
       "      <th>Not Available</th>\n",
       "      <th>Called deployment predict endpoint</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            Actions Needed\n",
       "Step      Status        Details                                                           \n",
       "initiate  Done          Initiated the model                                               \n",
       "prepare() Done          Generated runtime.yaml                                            \n",
       "                        Generated score.py                                                \n",
       "                        Serialized model                                                  \n",
       "                        Populated metadata(Custom, Taxonomy and Provenance)               \n",
       "verify()  Done          Local tested .predict from score.py                               \n",
       "save()    Done          Conducted Introspect Test                                         \n",
       "                        Uploaded artifact to model catalog                                \n",
       "deploy()  DELETED       Deployed the model                                                \n",
       "predict() Not Available Called deployment predict endpoint                                "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_model.summary_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf7a867",
   "metadata": {},
   "source": [
    "Use the `.delete_model()` method in a `ModelCatalog` object to delete the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb8e7203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelCatalog(compartment_id=os.environ['NB_SESSION_COMPARTMENT_OCID']).delete_model(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72d3213",
   "metadata": {},
   "source": [
    "The next cell removes the model artifacts that were stored on your local drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db670dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmtree(artifact_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c456d5",
   "metadata": {},
   "source": [
    "<a id='ref'></a>\n",
    "# References\n",
    "- [ADS Library Documentation](https://docs.cloud.oracle.com/en-us/iaas/tools/ads-sdk/latest/index.html)\n",
    "- [Data Science YouTube Videos](https://www.youtube.com/playlist?list=PLKCk3OyNwIzv6CWMhvqSB_8MLJIZdO80L)\n",
    "- [OCI Data Science Documentation](https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm)\n",
    "- [Oracle Data & AI Blog](https://blogs.oracle.com/datascience/)\n",
    "- [Understanding Conda Environments](https://docs.cloud.oracle.com/en-us/iaas/data-science/using/use-notebook-sessions.htm#conda_understand_environments)\n",
    "- [Use Resource Manager to Configure Your Tenancy for Data Science](https://docs.cloud.oracle.com/en-us/iaas/data-science/using/orm-configure-tenancy.htm)\n",
    "- [`runtime.yaml`](https://docs.content.oci.oracleiaas.com/en-us/iaas/data-science/using/model_runtime_yaml.htm#model_runtime_yaml)\n",
    "- [`score.py`](https://docs.content.oci.oracleiaas.com/en-us/iaas/data-science/using/model_score_py.htm#model_score_py)\n",
    "- [Model artifact](https://docs.content.oci.oracleiaas.com/en-us/iaas/data-science/using/models_saving_catalog.htm#create-models)\n",
    "- [ONNX API Summary](http://onnx.ai/sklearn-onnx/api_summary.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec4a735",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow28_p38_cpu_v1]",
   "language": "python",
   "name": "conda-env-tensorflow28_p38_cpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
