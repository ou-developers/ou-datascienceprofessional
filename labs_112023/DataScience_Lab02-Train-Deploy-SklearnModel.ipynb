{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oracle Data Science service sample notebook.\n",
    "\n",
    "Copyright (c) 2021-2022 Oracle, Inc.<br>\n",
    "Licensed under the Universal Permissive License v 1.0 as shown at https://oss.oracle.com/licenses/upl.\n",
    "</font>\n",
    "\n",
    "***\n",
    "# <font> Predicting Employee Attrition with ADS</font>\n",
    "<p style=\"margin-left:10%; margin-right:10%;\">by the <font color=\"teal\">Oracle Cloud Infrastructure Data Science Service.</font></p>\n",
    "\n",
    "***\n",
    "\n",
    "## Overview:\n",
    "\n",
    "This notebook uses an employee attrition dataset. It is a synthetic dataset that contains information about employees and if they have left the company or not. To understand the data, you start by doing an exploratory data analysis (EDA). This is followed by creating a model using `scikit-learn`. The model is used to make predictions and evaluate the model's performance on new data. Then the model is prepared and saved to the Model Catalog using Oracle's Accelerated Data Science, (`ADS`) library.\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "<font color=gray>Datasets are provided as a convenience.  Datasets are considered Third Party Content and are not considered Materials under Your agreement with Oracle applicable to the Services.  You can access the `orcl_attrition` dataset license [here](oracle_data/UPL.txt). Dataset `orcl_attrition` is distributed under UPL license. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please select the  pubhished conda envionment data-science-gmlv1_0_v1 before proceeding further. The version of ADS installed with this conda environment is 2.8.11. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ads\n",
    "import io\n",
    "import joblib \n",
    "import logging\n",
    "import numpy as np  \n",
    "import os\n",
    "import pandas as pd\n",
    "import sys \n",
    "import warnings\n",
    "import tempfile\n",
    "\n",
    "from ads.common.model import ADSModel\n",
    "from ads.common.model_artifact import ModelArtifact\n",
    "from ads.common.model_export_util import prepare_generic_model\n",
    "from ads.dataset.factory import DatasetFactory\n",
    "from ads.dataset.label_encoder import DataFrameLabelEncoder\n",
    "from ads.evaluations.evaluator import ADSEvaluator\n",
    "from collections import defaultdict\n",
    "from os import path \n",
    "from os.path import expanduser\n",
    "from os.path import join\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import get_scorer\n",
    "from ads.common.model_artifact import ModelArtifact\n",
    "from ads.config import NB_SESSION_OCID\n",
    "from ads.config import PROJECT_OCID\n",
    "from ads.config import NB_SESSION_COMPARTMENT_OCID\n",
    "\n",
    "from ads.model.framework.sklearn_model import SklearnModel\n",
    "\n",
    "ads.set_auth(auth='resource_principal') \n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  O  o-o   o-o\n",
      " / \\ |  \\ |\n",
      "o---o|   O o-o\n",
      "|   ||  /     |\n",
      "o   oo-o  o--o\n",
      "\n",
      "ads v2.8.11\n",
      "oci v2.114.0\n",
      "ocifs v1.1.3\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ads.hello()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='binaryclassifition'></a>\n",
    "# Binary Classification\n",
    "\n",
    "Binary classification is a technique of classifying observations into one of two categories. In this notebook, the two groups are those employees that will leave the organization and those that will not.\n",
    "\n",
    "Given the features in the data, the model will determine the optimal criteria for classifying an observation as leaving or not leaving. This optimization is based on the training data. However, some data will be excluded from the training data so that the model's performance can be evaluated. Models can over-fit on the training data, that is learn the noise in a dataset. Models can also under-fit the data, meaning that it does not learn the important characteristics of the relationships between the predictors and the target variable. Further, the model learns from the training data but its predictive power on the training data is not a good measure of the model's performance. Therefore, a test set of data is withheld from the full data set so that model's performance on an unseen set of data can be evaluated.\n",
    "\n",
    "The evaluation will be done using classic measures for fit for binary classification. These would be metrics such as specificity, sensitivity, accuracy, area under the ROC curve, lift, gain, and several others.\n",
    "\n",
    "# Open and Visualize the Dataset using `ADS`\n",
    "\n",
    "<a id='data'></a>\n",
    "## Dataset\n",
    "\n",
    "This is a synthetic data set which contains 1,470 observations. There are 36 features, where 22 are ordinal, 11 are categorical, and 3 are constant values. The data contains demographic information, compensation level, job characteristics, job satisfaction, and employee performance. The data is imbalanced as fewer employees leave than stay.\n",
    "\n",
    "The first step is to load the dataset. To do this the `DatasetFactory` singleton object will be used. It is part of the `ADS` SDK. It is a powerful class to work with datasets from different sources as you can store metadata such as what column is the target and what type of modeling problem is trying to be solved. In this case, it is a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d2dae6a4944031b0847089a24703f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "employees = DatasetFactory.open(\"/opt/notebooks/ads-examples/oracle_data/orcl_attrition.csv\", \n",
    "                                target=\"Attrition\").set_positive_class('Yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='trans'></a>\n",
    "# Transformation Recommendations\n",
    "\n",
    "`ADS` can help with feature engineering by automatically transforming datasets. For example, it can fix class imbalance by up or downsampling. This is just one example of the many transforms that `ADS` can apply. You can have `ADS` perform an analysis of the data and automatically apply the appropriate transformations to improve a model's performance. This is done with the `.auto_transform()` method. The `.suggest_recommendations()` method allows you to explore the suggested transforms using the notebook's UI and select the transformations that you would like it to make.\n",
    "\n",
    "All ADS datasets are immutable; any transforms that are applied result in a new dataset. In this example, the notebook will perform automatic transformations on the data, and it will also fix the class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transformed_ds = employees.auto_transform(fix_imbalance=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data should be split into training and test sets. This can be done using the `.train_test_split()`. The following cell uses the parameter `test_size` to indicate that it wants 80% of the data to be allocated to the training set and the remaining 20% will go to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = transformed_ds.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Random Forest Model \n",
    "\n",
    "The next cell trains a Randow Forest model. It use the sklearn `Pipeline()` object to assemble the data transformations and model estimators into a single object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.X.copy()\n",
    "y = train.y.copy()\n",
    "\n",
    "Xtest = test.X.copy()\n",
    "ytest = test.y.copy()\n",
    "\n",
    "le = DataFrameLabelEncoder()\n",
    "X = le.fit_transform(X)\n",
    "Xtest = le.fit_transform(Xtest)\n",
    "\n",
    "sk_clf = RandomForestClassifier(random_state=42)\n",
    "sk_clf.fit(X, y)\n",
    "\n",
    "sk_model = make_pipeline(le, sk_clf)\n",
    "\n",
    "my_model = ADSModel.from_estimator(sk_model, name=sk_clf.__class__.__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eval'></a>\n",
    "# Evaluate the Model\n",
    "\n",
    "One of the key advantages of `ADS` is the ability to quickly evaluate any regression or classification model. While `ADS` has many built-in evaluation techniques, it supports the ability to provide your own evaluation function. You would provide a series of the true dependent variable value and another series of the predicted value. Then any esoteric calculation can be performed. This notebook uses the built-in performance metrics as these are sufficient for binary classification model evaluation.\n",
    "\n",
    "The next cell creates the plots that are commonly used to evaluate model performance. These include the precision, recall, ROC, lift, and gain plots. Each model under study is plotted together, allowing for easy comparison. In addition, the normalized confusion matrices are provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:ads.common:ADSModel is being deprecated. Users should instead use GenericModel or one of its subclasses. More information here: https://accelerated-data-science.readthedocs.io/en/latest/user_guide/model_registration/introduction.html#register\n"
     ]
    }
   ],
   "source": [
    "evaluator = ADSEvaluator(test, models=[my_model], \n",
    "                         training_data=train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These metrics suggest that the model is not much better than chance. There is obviously a lot of work that would need to be done to improve the model's overall performance.\n",
    "\n",
    "There are a number of common metrics that are used to assess the quality of a model. `ADS` provides a convenient method to compare the models and highlights the model with the highest score in each metric. The following cell computes the metrics using the test and training datasets. It demonstrates that the model is a perfect classifier of the training data. It also demonstrates that on the test data, the model has a lot of room for improvement. The significant difference between the training and test metrics is a strong indication that the model is overfitting.\n",
    "\n",
    "The goal of this exercise is to create a model, not an ideal model. Therefore, the next step is to prepare the model for productionalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b1d7e_row0_col0, #T_b1d7e_row1_col0, #T_b1d7e_row2_col0, #T_b1d7e_row3_col0, #T_b1d7e_row4_col0, #T_b1d7e_row5_col0 {\n",
       "  background-color: lightgreen;\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b1d7e_\" class=table>\n",
       "  <caption><div align=\"left\"><b style=\"font-size:20px;\">Evaluation Metrics (testing data):</b></div></caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >RandomForestClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b1d7e_level0_row0\" class=\"row_heading level0 row0\" >Accuracy</th>\n",
       "      <td id=\"T_b1d7e_row0_col0\" class=\"data row0 col0\" >0.9636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1d7e_level0_row1\" class=\"row_heading level0 row1\" >Hamming distance</th>\n",
       "      <td id=\"T_b1d7e_row1_col0\" class=\"data row1 col0\" >0.0364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1d7e_level0_row2\" class=\"row_heading level0 row2\" >Precision</th>\n",
       "      <td id=\"T_b1d7e_row2_col0\" class=\"data row2 col0\" >0.9669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1d7e_level0_row3\" class=\"row_heading level0 row3\" >Recall</th>\n",
       "      <td id=\"T_b1d7e_row3_col0\" class=\"data row3 col0\" >0.9590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1d7e_level0_row4\" class=\"row_heading level0 row4\" >F1</th>\n",
       "      <td id=\"T_b1d7e_row4_col0\" class=\"data row4 col0\" >0.9630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1d7e_level0_row5\" class=\"row_heading level0 row5\" >ROC AUC</th>\n",
       "      <td id=\"T_b1d7e_row5_col0\" class=\"data row5 col0\" >0.9912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_69d60_row0_col0, #T_69d60_row1_col0, #T_69d60_row2_col0, #T_69d60_row3_col0, #T_69d60_row4_col0, #T_69d60_row5_col0 {\n",
       "  background-color: lightgreen;\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_69d60_\" class=table>\n",
       "  <caption><div align=\"left\"><b style=\"font-size:20px;\">Evaluation Metrics (training data):</b></div></caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >RandomForestClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_69d60_level0_row0\" class=\"row_heading level0 row0\" >Accuracy</th>\n",
       "      <td id=\"T_69d60_row0_col0\" class=\"data row0 col0\" >0.9990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_69d60_level0_row1\" class=\"row_heading level0 row1\" >Hamming distance</th>\n",
       "      <td id=\"T_69d60_row1_col0\" class=\"data row1 col0\" >0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_69d60_level0_row2\" class=\"row_heading level0 row2\" >Precision</th>\n",
       "      <td id=\"T_69d60_row2_col0\" class=\"data row2 col0\" >1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_69d60_level0_row3\" class=\"row_heading level0 row3\" >Recall</th>\n",
       "      <td id=\"T_69d60_row3_col0\" class=\"data row3 col0\" >0.9980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_69d60_level0_row4\" class=\"row_heading level0 row4\" >F1</th>\n",
       "      <td id=\"T_69d60_row4_col0\" class=\"data row4 col0\" >0.9990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_69d60_level0_row5\" class=\"row_heading level0 row5\" >ROC AUC</th>\n",
       "      <td id=\"T_69d60_row5_col0\" class=\"data row5 col0\" >1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A binary classification model can have one of four outcomes for each prediction. A true-negative is an outcome where the model correctly predicts the negative case, and a false-negative is an outcome where when the model incorrectly predicts the negative case. A false-positive is when the model incorrectly predicts the positive case, and a true-positive is when the model correctly predicts the positive case. However, not all false-positive and false-negatives have the same importance. For example, a cancer test has a higher cost when it incorrectly says that a patient does not have cancer when they do. The `.calculate_cost()` method allows the cost to be computed for each model based on the cost of each class of prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  cost\n",
       "0  RandomForestClassifier   754"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.calculate_cost(tn_weight=1, fp_weight=3, fn_weight=2, tp_weight=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could register your model with OCI Data Science service through ADS. Alternatively, the Oracle Cloud Infrastructure (OCI) Console can be used by going to the Data Science projects page, selecting a project, then click Models. The models page shows the model artifacts that are in the model catalog for a given project.\n",
    "\n",
    "After a model and its artifacts are registered, they become available for other data scientists if they have the correct permissions.\n",
    "The ADS SDK automatically captures some of the metadata for you. It captures provenance, taxonomy, and some custom metadata.\n",
    "ADS has a set of framework specific classes that take your model and push it to production with a few quick steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:ads.common:In the future model input will be serialized by `cloudpickle` by default. Currently, model input are serialized into a dictionary containing serialized input data and original data type information.Set `model_input_serializer=\"cloudpickle\"` to use cloudpickle model input serializer.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate ads.model.framework.sklearn_model.SklearnModel\n",
    "sklearn_model = SklearnModel(\n",
    "    estimator=sk_clf, artifact_dir=tempfile.mkdtemp()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "The first step is to create a model serialization object. This object wraps your model and has a number of methods to assist in deploying it. There are different model classes for different model classes.\n",
    "After creating the model serialization object, the next step is to use the .prepare() method to create the model artifacts. The score.py file is created and it is customized to your model class. You may still need to modify it for your specific use case but this is generally not required. The .prepare() method also can be used to store metadata about the model, code used to create the model, input and output schema, and much more.\n",
    "\n",
    "We will used the published conda environment as inference and training conda environment. The published conda environment in this case resides in the bucket LAB_Conda and the path is given by  \"oci://LAB_Conda@ocuocictrng22/data-science-gmlv1_0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:root:                                                                                                                                                                                    ?, ?it/s]\n",
      "WARNING:root:Failed to retrieve the full conda pack path from slug. Pass conda pack path 'oci://<bucketname>@<namespace>/<path_to_conda>' instead of slug.\n",
      "WARNING:root:\n",
      "WARNING:root:Failed to retrieve the full conda pack path from slug. Pass conda pack path 'oci://<bucketname>@<namespace>/<path_to_conda>' instead of slug.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "algorithm: RandomForestClassifier\n",
       "artifact_dir:\n",
       "  /tmp/tmpi59m3lcc:\n",
       "  - - model.joblib\n",
       "    - .model-ignore\n",
       "    - score.py\n",
       "    - runtime.yaml\n",
       "    - output_schema.json\n",
       "    - input_schema.json\n",
       "framework: scikit-learn\n",
       "model_deployment_id: null\n",
       "model_id: null"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Autogenerate score.py, serialized model, runtime.yaml, input_schema.json and output_schema.json\n",
    "sklearn_model.prepare(\n",
    "    training_conda_env=\"oci://LAB_Conda@ocuocictrng22/data-science-gmlv1_0\" ,\n",
    "    inference_conda_env=\"oci://LAB_Conda@ocuocictrng22/data-science-gmlv1_0\" ,\n",
    "    X_sample=X,\n",
    "    y_sample=y,\n",
    "    force_overwrite=True,\n",
    "    ignore_introspection=True\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you make changes to the score.py file, call the .verify() method to confirm that the load_model() and predict() functions in this file are working. This speeds up your debugging as you do not need to deploy a model to test it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading model.joblib from model directory /tmp/tmpi59m3lcc ...\n",
      "Model is successfully loaded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 1, 1, 1, 0, 0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The verify method invokes the ``predict`` function defined inside ``score.py`` in the artifact_dir\n",
    "\n",
    "sklearn_model.verify(Xtest[1:10])[\"prediction\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .save() method is then used to store the model in the model catalog. Use a unique display name to identify the saved model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading model.joblib from model directory /tmp/tmpi59m3lcc ...\n",
      "Model is successfully loaded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Register scikit-learn model\n",
    "model1 = sklearn_model.save(display_name=\"Attrition-Nov09-23\",inference_conda_env=\"oci://LAB_Conda@ocuocictrng22/data-science-gmlv1_0\",ignore_introspection=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A call to the .deploy() method creates a load balancer and the instances needed to have an HTTPS access point to perform inference on the model. Using the .predict() method, you can send data to the model deployment endpoint and it will return the predictions. Kindly ensure to give a valid display name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "kind: deployment\n",
       "spec:\n",
       "  createdBy: ocid1.datasciencenotebooksession.oc1.phx.amaaaaaas5adu2iacdwunpxq54h2xr2yjjfcyynvbzdxwmjzpv2qtbbm5vca\n",
       "  definedTags:\n",
       "    Oracle-Tags:\n",
       "      CreatedOn: '2023-11-09T09:23:43.232Z'\n",
       "  displayName: Attrition-Nov09-23\n",
       "  id: ocid1.datasciencemodeldeployment.oc1.phx.amaaaaaas5adu2iauzp5w6fjusvwmh6ylyp6qb43dm5oudrqztfjqhjhlnzq\n",
       "  infrastructure:\n",
       "    kind: infrastructure\n",
       "    spec:\n",
       "      bandwidthMbps: 10\n",
       "      compartmentId: ocid1.compartment.oc1..aaaaaaaabu6pgqbwe4are4ke7uzkq44rbvbnxwhybhmplialatq54kdvq4jq\n",
       "      deploymentType: SINGLE_MODEL\n",
       "      policyType: FIXED_SIZE\n",
       "      projectId: ocid1.datascienceproject.oc1.phx.amaaaaaas5adu2iaa45m3uo4rgrpu4fzgpyltcsf4bn5grgpzlc675dmiprq\n",
       "      replica: 1\n",
       "      shapeConfigDetails:\n",
       "        memoryInGBs: 16.0\n",
       "        ocpus: 2.0\n",
       "      shapeName: VM.Standard.E4.Flex\n",
       "      webConcurrency: '10'\n",
       "    type: datascienceModelDeployment\n",
       "  lifecycleDetails: Creating compute resources.\n",
       "  lifecycleState: CREATING\n",
       "  modelDeploymentUrl: https://modeldeployment.us-phoenix-1.oci.customer-oci.com/ocid1.datasciencemodeldeployment.oc1.phx.amaaaaaas5adu2iauzp5w6fjusvwmh6ylyp6qb43dm5oudrqztfjqhjhlnzq\n",
       "  runtime:\n",
       "    kind: runtime\n",
       "    spec:\n",
       "      env:\n",
       "        WEB_CONCURRENCY: '10'\n",
       "      modelUri: ocid1.datasciencemodel.oc1.phx.amaaaaaas5adu2iao7xrvgrfadq2j2t34crur6oh3d4m7woph2pvt6rmxoiq\n",
       "    type: conda\n",
       "  timeCreated: 2023-11-09 09:23:43.802000+00:00\n",
       "type: modelDeployment"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deploy and create an endpoint for the RandomForest model\n",
    "sklearn_model.deploy(display_name=\"Attrition-Nov09-23\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Endpoint: {sklearn_model.model_deployment.url}\")\n",
    "\n",
    "sklearn_model.predict(Xtest)[\"prediction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [conda env:data-science-gmlv1_0_v1]",
   "language": "python",
   "name": "conda-env-data-science-gmlv1_0_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
